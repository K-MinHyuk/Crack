{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "R7Yop9b8rObj",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Import Library\n",
    "import sys\n",
    "import os\n",
    "import shutil\n",
    "import glob\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torchsummary import summary\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "ChT_OrGRtsVh",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#데이터를 배열로 초기화\n",
    "# data = {}\n",
    "# data['crack'] = []\n",
    "# data['uncrack'] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c0MS7hUktsZu",
    "outputId": "07a1c350-a35d-479d-b18b-f5a546e573ff",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Crack Data\n",
    "# src = 'archive/Positive'\n",
    "# for jpgImage in glob.iglob(os.path.join(src, '*jpg')):\n",
    "#     data['crack'].append(jpgImage)\n",
    "# print(len(data['crack']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "P0ngL-Ujtsby",
    "outputId": "8df797f6-7cf3-4ee9-b671-d9bcf56f0191",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Uncrack Data\n",
    "# src = 'archive/Negative'\n",
    "# for jpgImage in glob.iglob(os.path.join(src, '*jpg')):\n",
    "#     data['uncrack'].append(jpgImage)\n",
    "# print(len(data['uncrack']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "TAKBxHt0tsf0",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Create File\n",
    "# os.mkdir('master_data_concrete')\n",
    "# os.mkdir('master_data_concrete/train')\n",
    "# os.mkdir('master_data_concrete/test')\n",
    "# os.mkdir('master_data_concrete/valid')\n",
    "\n",
    "# os.mkdir('master_data_concrete/train/crack')\n",
    "# os.mkdir('master_data_concrete/train/uncrack')\n",
    "# os.mkdir('master_data_concrete/test/crack')\n",
    "# os.mkdir('master_data_concrete/test/uncrack')\n",
    "# os.mkdir('master_data_concrete/valid/crack')\n",
    "# os.mkdir('master_data_concrete/valid/uncrack')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9ryQuaD7LVfM",
    "outputId": "daf62041-4aaa-4a8a-b9a8-7c3f3a0c1a81",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Data shuffle\n",
    "\n",
    "# X = data['crack'] #Data\n",
    "# Y = np.zeros((len(data['crack']))) #Labels\n",
    "\n",
    "# #train : validation = 60 : 40\n",
    "# X_T, X_test, Y_T, Y_test = train_test_split(X,Y, test_size=0.2)\n",
    "# X_train, X_valid, Y_train, Y_valid = train_test_split(X_T, Y_T, test_size=0.4)\n",
    "# # assert len(X_train) == len(data['crack'])/10*6\n",
    "\n",
    "# #Data Check\n",
    "# print('X_train Data list =',len(X_train), '   X_train Label list =',len(Y_train))\n",
    "# print('X_valid Data list =',len(X_valid), '   X_valid Label list =',len(Y_valid))\n",
    "# print('X_test Data list =',len(X_test), '   X_test Label list =',len(Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "bHT7yADgtshw",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#image copy\n",
    "\n",
    "# base_dest = 'master_data_concrete'\n",
    "\n",
    "# #copy training  images of crack type\n",
    "# for image in tqdm(X_train):\n",
    "#         dest = os.path.join(base_dest, 'train', 'crack')\n",
    "#         shutil.copy(image, dest)\n",
    "\n",
    "# #copy testing images of crack type\n",
    "# for image in tqdm(X_test):\n",
    "#         dest = os.path.join(base_dest, 'test', 'crack')\n",
    "#         shutil.copy(image, dest)\n",
    "        \n",
    "# for image in tqdm(X_valid):\n",
    "#     dest = os.path.join(base_dest, 'valid', 'crack')\n",
    "#     shutil.copy(image, dest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BP1LsB7UykUL",
    "outputId": "e9333cde-226b-4220-850c-09638fba59eb",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Data shuffle\n",
    "# X = data['uncrack'] #Data\n",
    "# Y = np.zeros((len(data['uncrack']))) #Labels\n",
    "\n",
    "# #train : validation = 60 : 40\n",
    "# X_T, X_test, Y_T, Y_test = train_test_split(X,Y, test_size=0.2)\n",
    "# X_train, X_valid, Y_train, Y_valid = train_test_split(X_T, Y_T, test_size=0.4)\n",
    "# # assert len(X_train) == len(data['crack'])/10*6\n",
    "\n",
    "# #Data Check\n",
    "# print('X_train Data list =',len(X_train), '   X_train Label list =',len(Y_train))\n",
    "# print('X_valid Data list =',len(X_valid), '   X_valid Label list =',len(Y_valid))\n",
    "# print('X_test Data list =',len(X_test), '   X_test Label list =',len(Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "bHT7yADgtshw",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#image copy\n",
    "\n",
    "# base_dest = 'master_data_concrete'\n",
    "\n",
    "# #copy training  images of crack type\n",
    "# for image in tqdm(X_train):\n",
    "#         dest = os.path.join(base_dest, 'train', 'uncrack')\n",
    "#         shutil.copy(image, dest)\n",
    "\n",
    "# #copy testing images of crack type\n",
    "# for image in tqdm(X_test):\n",
    "#         dest = os.path.join(base_dest, 'test', 'uncrack')\n",
    "#         shutil.copy(image, dest)\n",
    "        \n",
    "# for image in tqdm(X_valid):\n",
    "#     dest = os.path.join(base_dest, 'valid', 'uncrack')\n",
    "#     shutil.copy(image, dest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = 'master_data_concrete'\n",
    "train_transform = transforms.Compose([transforms.Resize(224),\n",
    "                                      transforms.Grayscale(),\n",
    "                                      transforms.RandomHorizontalFlip(),\n",
    "                                      transforms.ToTensor()\n",
    "                                     ])\n",
    "train_dataset = datasets.ImageFolder(data + '/train', transform=train_transform)\n",
    "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=10, shuffle=True)\n",
    "valid_transform = transforms.Compose([transforms.Resize(224),\n",
    "                                      transforms.Grayscale(),\n",
    "                                      transforms.ToTensor()\n",
    "                                     ])\n",
    "valid_dataset = datasets.ImageFolder(data + '/valid', transform=valid_transform)\n",
    "valid_dataloader = torch.utils.data.DataLoader(valid_dataset, batch_size=10, shuffle=True)\n",
    "test_transform = transforms.Compose([transforms.Resize(224),\n",
    "                                      transforms.Grayscale(),\n",
    "                                      transforms.ToTensor(),\n",
    "                                    ])\n",
    "test_dataset = datasets.ImageFolder(data + '/test', transform=test_transform)\n",
    "test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=10, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use Cuda!!\n"
     ]
    }
   ],
   "source": [
    "# define the CNN architecture\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        # convolutional layer (sees 224 x 224 x 1 image tensor)\n",
    "        self.conv1 = nn.Conv2d(1, 16, 3, padding=1)\n",
    "        # convolutional layer (sees 112 x 112 x 16 tensor)\n",
    "        self.conv2 = nn.Conv2d(16, 32, 3, padding=1)\n",
    "        # convolutional layer (sees 56 x 56 x 32 tensor)\n",
    "        self.bn1 = torch.nn.BatchNorm2d(16)\n",
    "        \n",
    "        self.bn2 = torch.nn.BatchNorm2d(32)\n",
    "        \n",
    "        # max pooling layer\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        # linear layer (56 * 56 * 32 -> 500)\n",
    "        self.fc1 = nn.Linear(56 * 56 * 32, 500)\n",
    "        # linear layer (500 -> 2)\n",
    "        self.fc2 = nn.Linear(500, 2)\n",
    "        \n",
    "        \n",
    "        # dropout layer (p=0.25)\n",
    "        self.dropout = nn.Dropout(0.25)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # add sequence of convolutional and max pooling layers\n",
    "        x = self.pool(self.bn1(F.relu(self.conv1(x))))\n",
    "        x = self.pool(self.bn2(F.relu(self.conv2(x))))\n",
    "        # flatten image input\n",
    "        x = x.view(-1, 56 * 56 * 32)\n",
    "        # add dropout layer\n",
    "        x = self.dropout(x)\n",
    "        # add 1st hidden layer, with relu activation function\n",
    "        x = F.relu(self.fc1(x))\n",
    "        # add dropout layer\n",
    "        x = self.dropout(x)\n",
    "        # add 2nd hidden layer, with relu activation function\n",
    "        x = F.log_softmax(self.fc2(x),dim=1)\n",
    "        return x\n",
    "\n",
    "# create a complete CNN\n",
    "model = Net()\n",
    "train_on_gpu = torch.cuda.is_available()\n",
    "# move tensors to GPU if CUDA is available\n",
    "if train_on_gpu:\n",
    "    model.cuda()\n",
    "    print(\"Use Cuda!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 16, 224, 224]             160\n",
      "       BatchNorm2d-2         [-1, 16, 224, 224]              32\n",
      "         MaxPool2d-3         [-1, 16, 112, 112]               0\n",
      "            Conv2d-4         [-1, 32, 112, 112]           4,640\n",
      "       BatchNorm2d-5         [-1, 32, 112, 112]              64\n",
      "         MaxPool2d-6           [-1, 32, 56, 56]               0\n",
      "           Dropout-7               [-1, 100352]               0\n",
      "            Linear-8                  [-1, 500]      50,176,500\n",
      "           Dropout-9                  [-1, 500]               0\n",
      "           Linear-10                    [-1, 2]           1,002\n",
      "================================================================\n",
      "Total params: 50,182,398\n",
      "Trainable params: 50,182,398\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.19\n",
      "Forward/backward pass size (MB): 21.45\n",
      "Params size (MB): 191.43\n",
      "Estimated Total Size (MB): 213.07\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(model, (a.shape[1],a.shape[2],a.shape[3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(n_epochs, model, train_loader, train_on_gpu, optimizer, criterion, valid_loader):\n",
    "    valid_loss_min = np.Inf # track change in validation loss\n",
    "    t_loss = []\n",
    "    v_loss = []\n",
    "    for epoch in tqdm(range(1, n_epochs+1), desc='Epoch : '):\n",
    "\n",
    "        # keep track of training and validation loss\n",
    "        train_loss = 0.0\n",
    "        valid_loss = 0.0\n",
    "\n",
    "        ###################\n",
    "        # train the model #\n",
    "        ###################\n",
    "        model.train()\n",
    "        for data, target in tqdm(train_loader, desc='Train : ', leave=False):\n",
    "            # move tensors to GPU if CUDA is available\n",
    "            if train_on_gpu:\n",
    "                data, target = data.cuda(), target.cuda()\n",
    "            # clear the gradients of all optimized variables\n",
    "            optimizer.zero_grad()\n",
    "            # forward pass: compute predicted outputs by passing inputs to the model\n",
    "            output = model(data)\n",
    "            # calculate the batch loss\n",
    "            loss = criterion(output, target)\n",
    "            # backward pass: compute gradient of the loss with respect to model parameters\n",
    "            loss.backward()\n",
    "            # perform a single optimization step (parameter update)\n",
    "            optimizer.step()\n",
    "            # update training loss\n",
    "            train_loss += loss.item()*data.size(0)\n",
    "\n",
    "        ######################    \n",
    "        # validate the model #\n",
    "        ######################\n",
    "        with torch.no_grad():\n",
    "            model.eval()\n",
    "            for data, target in tqdm(valid_loader, desc='Validation : ', leave=False):\n",
    "                # move tensors to GPU if CUDA is available\n",
    "                if train_on_gpu:\n",
    "                    data, target = data.cuda(), target.cuda()\n",
    "                # forward pass: compute predicted outputs by passing inputs to the model\n",
    "                output = model(data)\n",
    "                # calculate the batch loss\n",
    "                loss = criterion(output, target)\n",
    "                # update average validation loss \n",
    "                valid_loss += loss.item()*data.size(0)\n",
    "\n",
    "        # calculate average losses\n",
    "        train_loss = train_loss/len(train_loader.sampler)\n",
    "        valid_loss = valid_loss/len(valid_loader.sampler)\n",
    "        t_loss.append(train_loss)\n",
    "        v_loss.append(valid_loss)\n",
    "        # print training/validation statistics \n",
    "        print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f}'.format(\n",
    "            epoch, train_loss, valid_loss))\n",
    "\n",
    "        # save model if validation loss has decreased\n",
    "        if valid_loss <= valid_loss_min:\n",
    "            print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(\n",
    "            valid_loss_min,\n",
    "            valid_loss))\n",
    "            torch.save(model.state_dict(), 'model_cifar.pt')\n",
    "            valid_loss_min = valid_loss\n",
    "    return t_loss, v_loss, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "094ceebc54634f5181a7288dc4452201",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch :   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train :   0%|          | 0/1920 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation :   0%|          | 0/1280 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 \tTraining Loss: 0.125394 \tValidation Loss: 0.086225\n",
      "Validation loss decreased (inf --> 0.086225).  Saving model ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train :   0%|          | 0/1920 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation :   0%|          | 0/1280 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2 \tTraining Loss: 0.037321 \tValidation Loss: 0.028606\n",
      "Validation loss decreased (0.086225 --> 0.028606).  Saving model ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train :   0%|          | 0/1920 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation :   0%|          | 0/1280 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3 \tTraining Loss: 0.022927 \tValidation Loss: 0.033721\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train :   0%|          | 0/1920 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation :   0%|          | 0/1280 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4 \tTraining Loss: 0.031639 \tValidation Loss: 0.019940\n",
      "Validation loss decreased (0.028606 --> 0.019940).  Saving model ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train :   0%|          | 0/1920 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation :   0%|          | 0/1280 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 \tTraining Loss: 0.009349 \tValidation Loss: 0.022403\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train :   0%|          | 0/1920 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation :   0%|          | 0/1280 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6 \tTraining Loss: 0.010009 \tValidation Loss: 0.027890\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train :   0%|          | 0/1920 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation :   0%|          | 0/1280 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7 \tTraining Loss: 0.012028 \tValidation Loss: 0.030653\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train :   0%|          | 0/1920 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation :   0%|          | 0/1280 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8 \tTraining Loss: 0.009176 \tValidation Loss: 0.024736\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train :   0%|          | 0/1920 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation :   0%|          | 0/1280 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9 \tTraining Loss: 0.005109 \tValidation Loss: 0.045065\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train :   0%|          | 0/1920 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation :   0%|          | 0/1280 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 \tTraining Loss: 0.005340 \tValidation Loss: 0.025708\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 10\n",
    "train_loader = train_dataloader\n",
    "train_on_gpu = torch.cuda.is_available()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "criterion = nn.NLLLoss()\n",
    "valid_loader = valid_dataloader\n",
    "train_loss, valid_loss, model = train(n_epochs, model, train_loader, train_on_gpu, optimizer, criterion, valid_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x232a1e35ac0>]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_loss)\n",
    "plt.plot(valid_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('model_cifar.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(batch_size, model, test_dataloader, train_on_gpu, criterion, classes):\n",
    "    test_loss = 0.0\n",
    "    class_correct = list(0. for i in range(10))\n",
    "    class_total = list(0. for i in range(10))\n",
    "\n",
    "    model.eval()\n",
    "    # iterate over test data\n",
    "    for data, target in tqdm(test_dataloader):\n",
    "        # move tensors to GPU if CUDA is available\n",
    "        if train_on_gpu:\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "        # forward pass: compute predicted outputs by passing inputs to the model\n",
    "        output = model(data)\n",
    "        # calculate the batch loss\n",
    "        loss = criterion(output, target)\n",
    "        # update test loss \n",
    "        test_loss += loss.item()*data.size(0)\n",
    "        # convert output probabilities to predicted class\n",
    "        _, pred = torch.max(output, 1)    \n",
    "        # compare predictions to true label\n",
    "        correct_tensor = pred.eq(target.data.view_as(pred))\n",
    "        correct = np.squeeze(correct_tensor.numpy()) if not train_on_gpu else np.squeeze(correct_tensor.cpu().numpy())\n",
    "        # calculate test accuracy for each object class\n",
    "        for i in range(batch_size):\n",
    "            label = target.data[i]\n",
    "            class_correct[label] += correct[i].item()\n",
    "            class_total[label] += 1\n",
    "\n",
    "    # average test loss\n",
    "    test_loss = test_loss/len(test_dataloader.dataset)\n",
    "    print('Test Loss: {:.6f}\\n'.format(test_loss))\n",
    "\n",
    "    for i in range(len(classes)):\n",
    "        if class_total[i] > 0:\n",
    "            print('Test Accuracy of %5s: %2d%% (%2d/%2d)' % (\n",
    "                classes[i], 100 * class_correct[i] / class_total[i],\n",
    "                np.sum(class_correct[i]), np.sum(class_total[i])))\n",
    "        else:\n",
    "            print('Test Accuracy of %5s: N/A (no training examples)' % (classes[i]))\n",
    "\n",
    "    print('\\nTest Accuracy (Overall): %2d%% (%2d/%2d)' % (\n",
    "        100. * np.sum(class_correct) / np.sum(class_total),\n",
    "        np.sum(class_correct), np.sum(class_total)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b72b051f42e47b5970055ef30455438",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/800 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.013554\n",
      "\n",
      "Test Accuracy of Crack: 99% (3973/4000)\n",
      "Test Accuracy of Uncrack: 99% (3990/4000)\n",
      "\n",
      "Test Accuracy (Overall): 99% (7963/8000)\n"
     ]
    }
   ],
   "source": [
    "train_on_gpu = torch.cuda.is_available()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "criterion = nn.NLLLoss()\n",
    "batch_size = 10\n",
    "classes = ['Crack', 'Uncrack']\n",
    "test(batch_size, model, test_dataloader, train_on_gpu, criterion, classes)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "CustomModel624.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
